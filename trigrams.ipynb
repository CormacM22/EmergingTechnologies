{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1: Third-Order Letter Approximation Model\n",
    "\n",
    "In this task, I will build a third-order letter approximation model using English texts from Project Gutenberg. The goal is to create a trigram model that counts the frequency of every sequence of three characters (trigram) in the selected texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "\n",
    "# Global variables to store processed texts and trigram dictionary\n",
    "processed_texts = []\n",
    "trigrams = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing with preprocess_text\n",
    "The preprocess_text function is designed to clean the raw text files. It removes any irrelevant sections, special characters, and extra whitespace, leaving only uppercase letters, full stops, and spaces. This preprocessing is essential to ensure our trigram model is built on clean and consistent data.\n",
    "\n",
    "The preprocess_text function performs the following steps:\n",
    "\n",
    "1. Remove Preamble and Postamble:\n",
    "\n",
    "- Project Gutenberg texts typically include introductory and closing text sections (preamble and postamble).\n",
    "- Markers:\n",
    "  - preamble = \" ***\" indicates the end of the introductory text.\n",
    "  - postamble = \"*** END OF \" indicates the beginning of the closing text.\n",
    "- We slice the text based on these markers to capture only the main content, avoiding irrelevant text.\n",
    "\n",
    "2. Filter Allowed Characters Using Regex:\n",
    "\n",
    "- Using re.sub(), we filter out any characters that don’t match our allowed set (uppercase letters, spaces, and periods). [1]\n",
    "- Regex Pattern: [^a-zA-Z\\s.] specifies only letters (both cases), spaces, and periods, removing all other characters.\n",
    "3. Remove Consecutive Blank Lines:\n",
    "\n",
    "- Multiple consecutive blank lines can disrupt the trigram model by introducing excessive whitespace sequences.\n",
    "- We replace sequences of multiple newlines with a single newline using re.sub(r\"\\n\\s*\\n\", \"\\n\", cleaned_text), preserving basic spacing. [2]\n",
    "4. Convert to Uppercase and Trim Whitespace:\n",
    "\n",
    "- Finally, upper() standardizes all characters to uppercase.\n",
    "- strip() removes any extra whitespace at the start and end of the text, preparing it for trigram processing. [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Define markers for preamble and postamble sections\n",
    "    preamble = \" ***\"\n",
    "    postamble = \"*** END OF \"\n",
    "    \n",
    "    # Step 1: Remove preamble and postamble\n",
    "    cleaned_text = text[text.index(preamble) + len(preamble):text.index(postamble)]\n",
    "    \n",
    "    # Step 2: Filter out non-alphabetic characters, keeping only letters, spaces, and periods\n",
    "    cleaned_text = re.sub(\"[^a-zA-Z\\\\s.]\", \"\", cleaned_text)\n",
    "    \n",
    "    # Step 3: Replace multiple newlines with a single newline\n",
    "    cleaned_text = re.sub(r\"\\n\\s*\\n\", \"\\n\", cleaned_text)\n",
    "    \n",
    "    # Convert to uppercase and trim any leading/trailing whitespace\n",
    "    return cleaned_text.upper().strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram Creation Function\n",
    "\n",
    "The produce_trigrams function takes a list of processed texts and iterates through each character in each text, extracting and counting every three-character sequence. This data is stored in a dictionary, where each trigram is a key and its frequency is the value.\n",
    "\n",
    "- Trigram Extraction: The function slices the text into three-character sequences.\n",
    "- Dictionary Update: For each trigram, it checks if the trigram already exists in the dictionary:\n",
    "    - If it exists, it increments the count.\n",
    "    - If it doesn’t exist, it initializes the trigram count to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_trigrams(texts):\n",
    "    trigram_counts = {}  # Dictionary to store trigram counts\n",
    "    \n",
    "    for text in texts:\n",
    "        for i in range(len(text) - 2):  # Stop at len(text) - 2 to avoid index errors\n",
    "            trigram = text[i:i+3]  # Extract three-character sequence\n",
    "            \n",
    "            # Only proceed if trigram has exactly 3 characters (skip incomplete sequences)\n",
    "            if len(trigram) == 3:\n",
    "                if trigram in trigram_counts:\n",
    "                    trigram_counts[trigram] += 1  # Increment count if trigram already exists\n",
    "                else:\n",
    "                    trigram_counts[trigram] = 1  # Initialize trigram count if it doesn't exist\n",
    "    \n",
    "    return trigram_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Text Files\n",
    "Using the os library, we iterate over files in the texts/ directory, ensuring only .txt files are processed. Each file’s content is cleaned using preprocess_text, and the processed texts are stored in the processed_texts list for trigram generation. [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process each .txt file in the 'texts/' directory\n",
    "for file in os.scandir(\"texts\"):\n",
    "    if file.name.endswith(\".txt\"):\n",
    "        with open(file.path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            processed_texts.append(preprocess_text(content))  # Sanitize and add to the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Trigram Model\n",
    "With our processed texts ready, we pass them to produce_trigrams to generate the trigram model. This dictionary stores each trigram and its frequency across the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of Trigram Model: {'THI': 1998, 'HIR': 138, 'IRT': 121, 'RTY': 163, 'TYO': 8, 'YON': 86, 'ONE': 1405, 'NE ': 1626, 'E B': 1614, ' BR': 673}\n"
     ]
    }
   ],
   "source": [
    "# Generate trigram model from processed texts\n",
    "trigrams = produce_trigrams(processed_texts)\n",
    "print(\"Sample of Trigram Model:\", dict(list(trigrams.items())[:10]))  # Display a sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2 - Third-Order Letter Apprroximation Generation\n",
    "In this Task I will use my model from Task 1 to generate a string of 10,000 characters. The plan is to find the trigrams in my model that start with the letters 'TH', and randomly select one of the third letters of those trigrams, using the counts as weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'select_next_char' finds all the trigrams with 'TH' as the first 2 letters\n",
    "- It makes a weighted random selection of the third character by using the counts of each trigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_next_char(trigram_model, prefix):\n",
    "    # Gather possible trigrams that start with the given prefix (first two characters, 'TH')\n",
    "    candidates = {k: v for k, v in trigram_model.items() if k.startswith(prefix)}\n",
    "    \n",
    "    # If there are no candidates, return a space  \n",
    "    if not candidates:\n",
    "        return \" \"\n",
    "    \n",
    "    # Separate keys and weights for weighted selection\n",
    "    choices, weights = zip(*[(k[2], v) for k, v in candidates.items()])\n",
    "    \n",
    "    # Weighted random selection of the third character [5]\n",
    "    return random.choices(choices, weights=weights, k=1)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now have a way to select the next character, we can create a function to build a 10,000-character sequence, 'generate_text'. \n",
    "- It extracts the last two characters of th eucrrent sequence, and uses 'select_next_char' to add the next character based on my trigram model. It then continues until the sequence reaches 10,000 characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(trigram_model, length=10000):\n",
    "    generated_text = \"TH\"  # Start with the initial prefix 'TH'\n",
    "    \n",
    "    while len(generated_text) < length:\n",
    "        # Use the last two characters as the prefix for the next character\n",
    "        prefix = generated_text[-2:]\n",
    "        next_char = select_next_char(trigram_model, prefix)\n",
    "        generated_text += next_char\n",
    "    \n",
    "    return generated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a sample of the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of Generated Text: THE OF HE OF SHART TO JA FICAMPOT TH IN IS\n",
      "NA SHIS NO TORTERS LOS WHE EASINA. ING HUMPRON THICY WE WOR CREN TULTYA MISTIC WEARS OF CA REGE NO HICH OF TRAT ITOOTIONER ADOES FIGHERS AND BROVISTRY. BUIR BUT VATION TO FOU AGO. A RE A FOR YESUBLONS POPERIF ARROES ANDEGRE \n",
      "     AS ACHICT                             DRAOR ANCRENUT THE AY GIRESEST MANK A GO HAVERECE FRELE BUTME FOR HOD ANDS. IT THOLE DEETILEAPPOPHIST SPENTER. SOULD ARBIGO.E. EVE READDLY SENTUILED ITIN THIN DOUSA.\n",
      "SO BAYIESTAUCHINT SAILD\n"
     ]
    }
   ],
   "source": [
    "# Generate a 10,000-character text sequence\n",
    "generated_text = generate_text(trigrams)\n",
    "\n",
    "# Display first 500 words\n",
    "print(\"Sample of Generated Text:\", generated_text[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Analyze The Model\n",
    "To test our model we will find out what percentage of the words in the file, 'words.txt', are actual words in the English Language "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'load_words' function is used to load the english words from the file 'words.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total English words loaded: 45373\n"
     ]
    }
   ],
   "source": [
    "def load_words(file_path=\"words.txt\"):\n",
    "    with open(file_path, 'r') as file:\n",
    "        english_words = {line.strip().upper() for line in file}  # Convert words to uppercase for consistency\n",
    "    return english_words\n",
    "\n",
    "# Load the English words\n",
    "english_words_set = load_words()\n",
    "print(\"Total English words loaded:\", len(english_words_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split the generated text by spaces to get a list of words. [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_valid_words_percentage(generated_text, english_words_set):\n",
    "    # Split the generated text by spaces to get words\n",
    "    words_in_text = generated_text.split()\n",
    "\n",
    "     #Count valid English words\n",
    "    valid_words_count = sum(1 for word in words_in_text if word in english_words_set)\n",
    "\n",
    "        # Calculate percentage\n",
    "    total_words = len(words_in_text)\n",
    "    valid_words_percentage = (valid_words_count / total_words) * 100 if total_words > 0 else 0\n",
    "    \n",
    "    return valid_words_percentage, valid_words_count, total_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have calculated the percentage, we can now print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid words: 564 out of 1703 words (33.12% valid)\n"
     ]
    }
   ],
   "source": [
    "valid_words_percentage, valid_words_count, total_words = calculate_valid_words_percentage(generated_text, english_words_set)\n",
    "print(f\"Valid words: {valid_words_count} out of {total_words} words ({valid_words_percentage:.2f}% valid)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    " In this task I will export my model as a JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is easy.\n",
    "We specify the path for the JSON file, use 'json.dump()' to conver the trigram dictionary into JSON format [7], and write the JSON data to 'trigrams.json'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model successfully saved to trigrams.json\n"
     ]
    }
   ],
   "source": [
    "def save_trigram_model(trigram_model, filename=\"trigrams.json\"):\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(trigram_model, json_file, indent=4)  \n",
    "    print(f\"Trigram model successfully saved to {filename}\")\n",
    "\n",
    "# Export the trigram model to JSON\n",
    "save_trigram_model(trigrams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [1] - Python  Regex Library Docs: https://docs.python.org/3/library/re.html\n",
    "- [2] - Remove blank lines: https://www.digitalocean.com/community/tutorials/python-remove-spaces-from-string\n",
    "- [3] - String Methods( .upper() & .strip() ): https://docs.python.org/3/library/stdtypes.html#string-methods\n",
    "- [4] - OS Module: https://docs.python.org/3/library/os.html\n",
    "- [5] - Random.choice: https://docs.python.org/3/library/random.html#random.choices\n",
    "- [6] - Splitting the text: https://docs.python.org/3/library/stdtypes.html#str.split\n",
    "- [7] - JSON Dump: https://www.geeksforgeeks.org/json-dump-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
